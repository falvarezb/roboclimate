# Deployment and execution

## AWS architecture

![aws architecture](roboclimateaws.png)

- There are two lambda functions ('weather' and 'forecast') that fetch data from the Internet and store it in an Elastic File System (EFS).

- Access to the EFS must be done through mount targets created in private subnets; for redundancy, two private subnets, each in a different avaliability zone, are created
- For a lambda function to be able to access the EFS, it must be connected to the private subnets containing the mount targets and mount the EFS in its local filesystem
- Once a lambda function is connected to a VPC, it can only access the Internet through that VPC, and therefore the corresponding Internet traffic must be routed from the private subnets to a public subnet containing a NAT instance that can reach the Internet Gateway.
- The NAT instance also plays the role of bastion host as it allows access to the resources in the private subnets
- In order to access the files generated by the lambda functions from outside AWS, an EC2 instance with the EFS mounted on it is created in one of the private subnets. See below how to forward files to this instance through the NAT instance.
- Lambda functions are executed according to the cron expression defined in the corresponding EventBridge schedulers

## Deploy process

### Create deployable artifact

Create a folder containing the source code and its dependencies by running

```sh { interactive=false }
./artifact_prep.sh weather
./artifact_prep.sh forecast
```

### Run terraform script

The first time, run

```sh
terraform init
```

If not logged-in on Terraform Cloud yet, run

```sh
terraform login
```

Then execute the script

```sh
terraform apply -var-file ../secrets.tfvars
```

Note: before running the script, it may be necessary to update the value of the variable `my_ip` in `secrets.tfvars`

### CSV files

In case CSV files need to be uploaded/downloaded to/from EFS (AWS Elastic File System), it can be done by running the following scripts.

By default, the local folder is

```sh
echo "$ROBOCLIMATE_CSV_FILES_PATH"
```

The default location can be overriden by providing an argument to the scripts

```sh
./upload_csv_files.sh
```

```sh
./download_csv_files.sh
```

__IMPORTANT__: 
- it may be necessary to add the private key to the ssh agent (`ssh-add <key_file>`)

- it may be necessary to re-run terraform with the current value of `my_ip` to update the security group that allows ssh access

Since the EC2 instance in the private subnet is only needed to upload/download csv files, it can be stopped for most of the time to save costs. The instance can be stopped and started with:

```sh
./efs_instance.sh stop
```

and

```sh
./efs_instance.sh start
```

respectively.

Logging into said instance can be done with:

```sh
./connefs.sh
```

### Provisioning EFS's EC2 instance

In case it is necessary to trigger the execution of the `user_data` once the EC2 instance has been created, the instance must be replaced

```sh
terraform apply -var-file ../secrets.tfvars -replace aws_instance.efs_instance
```
